{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Agent with Qdrant\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thierrypdamiba/qdrant-etl-cookbook/blob/main/notebooks/agents/rag_agent.ipynb)\n",
        "\n",
        "A retrieval-augmented generation agent that queries Qdrant for context and generates answers using an LLM.\n",
        "\n",
        "**Requirements:** Set `OPENAI_API_KEY` environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q \"qdrant-client[fastembed]>=1.13,<1.16\" openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from qdrant_client import QdrantClient\n",
        "\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seed some knowledge\n",
        "documents = [\n",
        "    \"HNSW indexing in Qdrant uses m=16 and ef_construct=100 by default. Increase m for better recall at the cost of memory.\",\n",
        "    \"Scalar quantization converts float32 vectors to int8, reducing memory by 4x with minimal accuracy loss.\",\n",
        "    \"Payload indexes should be created on fields you filter by frequently. Supported types: keyword, integer, float, geo, text.\",\n",
        "    \"Multi-tenancy in Qdrant is best achieved with a tenant_id payload field and a keyword index on it.\",\n",
        "    \"Snapshots can be created per-collection or as a full storage snapshot for disaster recovery.\",\n",
        "]\n",
        "\n",
        "qdrant.add(\n",
        "    collection_name=\"knowledge\",\n",
        "    documents=documents,\n",
        ")\n",
        "print(f\"Seeded {len(documents)} knowledge documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rag_agent(query: str, collection: str = \"knowledge\", top_k: int = 3):\n",
        "    \"\"\"Retrieve context from Qdrant, generate answer with LLM.\"\"\"\n",
        "    results = qdrant.query(\n",
        "        collection_name=collection,\n",
        "        query_text=query,\n",
        "        limit=top_k,\n",
        "    )\n",
        "\n",
        "    context = \"\\n\\n\".join([r.document for r in results])\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"Answer the user's question using the provided context. \"\n",
        "                    \"If the context doesn't contain the answer, say so.\"\n",
        "                ),\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\",\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"answer\": response.choices[0].message.content,\n",
        "        \"sources\": [r.document for r in results],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = rag_agent(\"How do I set up HNSW indexing?\")\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"\\nSources:\")\n",
        "for s in result[\"sources\"]:\n",
        "    print(f\"  - {s[:80]}...\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}