{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PostgreSQL to Qdrant\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thierrypdamiba/qdrant-etl-cookbook/blob/main/notebooks/etl/postgres_to_qdrant.ipynb)\n",
        "\n",
        "Extract records from PostgreSQL, embed text columns, and sync into Qdrant. This demo uses sqlite3 as a stand-in to keep it self-contained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q qdrant-client sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = QdrantClient(\":memory:\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample database (replace with psycopg2 + PostgreSQL in production)\n",
        "conn = sqlite3.connect(\":memory:\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"CREATE TABLE products (id INTEGER PRIMARY KEY, title TEXT, description TEXT)\")\n",
        "cursor.executemany(\n",
        "    \"INSERT INTO products (id, title, description) VALUES (?, ?, ?)\",\n",
        "    [\n",
        "        (1, \"Vector Database\", \"A database optimized for storing and querying vector embeddings\"),\n",
        "        (2, \"Search Engine\", \"Software for indexing and searching through large document collections\"),\n",
        "        (3, \"ML Platform\", \"End-to-end platform for training and deploying machine learning models\"),\n",
        "        (4, \"Data Pipeline\", \"ETL tool for extracting, transforming, and loading data between systems\"),\n",
        "        (5, \"API Gateway\", \"Service that manages and routes API requests with authentication\"),\n",
        "    ],\n",
        ")\n",
        "conn.commit()\n",
        "print(\"Sample database created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"pg_data\",\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cursor.execute(\"SELECT id, title, description FROM products\")\n",
        "\n",
        "points = []\n",
        "for row in cursor.fetchall():\n",
        "    record_id, title, description = row\n",
        "    text = f\"{title} {description}\"\n",
        "    embedding = model.encode(text).tolist()\n",
        "    points.append(\n",
        "        PointStruct(\n",
        "            id=record_id,\n",
        "            vector=embedding,\n",
        "            payload={\"title\": title, \"description\": description},\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if len(points) >= 100:\n",
        "        client.upsert(collection_name=\"pg_data\", points=points)\n",
        "        points = []\n",
        "\n",
        "if points:\n",
        "    client.upsert(collection_name=\"pg_data\", points=points)\n",
        "\n",
        "conn.close()\n",
        "print(f\"Loaded {cursor.lastrowid} records from database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search\n",
        "query_vector = model.encode(\"tool for processing data\").tolist()\n",
        "results = client.search(\n",
        "    collection_name=\"pg_data\",\n",
        "    query_vector=query_vector,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "for r in results:\n",
        "    print(f\"Score: {r.score:.4f} | {r.payload['title']}: {r.payload['description']}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
