{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract PDF Text and Load into Qdrant\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thierrypdamiba/qdrant-etl-cookbook/blob/main/notebooks/etl/pdf_to_qdrant.ipynb)\n",
        "\n",
        "Parse PDFs with PyMuPDF, chunk text with overlap, embed, and store in Qdrant for RAG pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q qdrant-client sentence-transformers PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = QdrantClient(\":memory:\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample PDF for demo\n",
        "pdf_path = Path(tempfile.mktemp(suffix=\".pdf\"))\n",
        "doc = fitz.open()\n",
        "\n",
        "pages_text = [\n",
        "    \"Qdrant is a vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points (vectors with an additional payload). Qdrant is tailored to extended filtering support.\",\n",
        "    \"HNSW (Hierarchical Navigable Small World) is the primary indexing algorithm used in Qdrant. It builds a multi-layer graph structure that enables efficient approximate nearest neighbor search. The key parameters are m (number of connections) and ef_construct (search depth during construction).\",\n",
        "    \"Quantization in Qdrant reduces memory usage by compressing vector representations. Scalar quantization converts float32 to int8, reducing memory by 4x. Binary quantization provides up to 32x reduction but works best with high-dimensional vectors like OpenAI embeddings.\",\n",
        "]\n",
        "\n",
        "for text in pages_text:\n",
        "    page = doc.new_page()\n",
        "    page.insert_text((72, 72), text, fontsize=12)\n",
        "\n",
        "doc.save(str(pdf_path))\n",
        "doc.close()\n",
        "print(f\"Created sample PDF with {len(pages_text)} pages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50):\n",
        "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
        "    chunks = []\n",
        "    for i in range(0, len(text), chunk_size - overlap):\n",
        "        chunk = text[i : i + chunk_size]\n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"pdf_collection\",\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = fitz.open(str(pdf_path))\n",
        "points = []\n",
        "point_id = 0\n",
        "\n",
        "for page_num, page in enumerate(doc):\n",
        "    text = page.get_text()\n",
        "    chunks = chunk_text(text)\n",
        "\n",
        "    for chunk in chunks:\n",
        "        embedding = model.encode(chunk).tolist()\n",
        "        points.append(\n",
        "            PointStruct(\n",
        "                id=point_id,\n",
        "                vector=embedding,\n",
        "                payload={\"text\": chunk, \"page\": page_num, \"source\": str(pdf_path)},\n",
        "            )\n",
        "        )\n",
        "        point_id += 1\n",
        "\n",
        "client.upsert(collection_name=\"pdf_collection\", points=points)\n",
        "print(f\"Loaded {point_id} chunks from {len(doc)} pages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search the PDF content\n",
        "query_vector = model.encode(\"How does quantization reduce memory?\").tolist()\n",
        "results = client.search(\n",
        "    collection_name=\"pdf_collection\",\n",
        "    query_vector=query_vector,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "for r in results:\n",
        "    print(f\"Score: {r.score:.4f} | Page {r.payload['page']}\")\n",
        "    print(f\"  {r.payload['text'][:120]}...\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
