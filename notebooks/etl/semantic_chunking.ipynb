{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Chunking for Better RAG\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thierrypdamiba/qdrant-etl-cookbook/blob/main/notebooks/etl/semantic_chunking.ipynb)\n",
        "\n",
        "Split documents into semantically coherent chunks instead of fixed-size windows. Uses embedding similarity to find natural breakpoints, then loads into Qdrant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q qdrant-client sentence-transformers numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = QdrantClient(\":memory:\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def semantic_chunk(text: str, model, threshold: float = 0.5, min_chunk_size: int = 50):\n",
        "    \"\"\"Split text into chunks at semantic breakpoints.\n",
        "    \n",
        "    Embeds each sentence, then splits where consecutive sentence\n",
        "    similarity drops below the threshold.\n",
        "    \"\"\"\n",
        "    # Split into sentences\n",
        "    sentences = [s.strip() for s in text.replace('\\n', ' ').split('.') if s.strip()]\n",
        "    if len(sentences) <= 1:\n",
        "        return [text]\n",
        "\n",
        "    # Embed all sentences\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Compute cosine similarity between consecutive sentences\n",
        "    similarities = []\n",
        "    for i in range(len(embeddings) - 1):\n",
        "        a, b = embeddings[i], embeddings[i + 1]\n",
        "        sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "        similarities.append(sim)\n",
        "\n",
        "    # Find breakpoints where similarity drops\n",
        "    chunks = []\n",
        "    current_chunk = [sentences[0]]\n",
        "\n",
        "    for i, sim in enumerate(similarities):\n",
        "        if sim < threshold and len('. '.join(current_chunk)) >= min_chunk_size:\n",
        "            chunks.append('. '.join(current_chunk) + '.')\n",
        "            current_chunk = [sentences[i + 1]]\n",
        "        else:\n",
        "            current_chunk.append(sentences[i + 1])\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append('. '.join(current_chunk) + '.')\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample document with distinct topics\n",
        "document = \"\"\"\n",
        "Qdrant is a vector similarity search engine. It provides a production-ready \n",
        "service with a convenient API. Qdrant supports filtering and payload indexing.\n",
        "\n",
        "Machine learning models convert data into vector embeddings. These embeddings \n",
        "capture semantic meaning in high-dimensional space. Similar items have vectors \n",
        "that are close together.\n",
        "\n",
        "Docker makes it easy to deploy Qdrant. You can use Docker Compose for \n",
        "production setups. Kubernetes is recommended for large-scale deployments \n",
        "with automatic scaling.\n",
        "\n",
        "Python is the most popular language for working with vector databases. \n",
        "The qdrant-client library provides a convenient interface. TypeScript \n",
        "and Rust clients are also available.\n",
        "\"\"\"\n",
        "\n",
        "# Compare fixed vs semantic chunking\n",
        "semantic_chunks = semantic_chunk(document, model, threshold=0.5)\n",
        "\n",
        "print(f\"Semantic chunks ({len(semantic_chunks)}):\")\n",
        "for i, chunk in enumerate(semantic_chunks):\n",
        "    print(f\"\\n  Chunk {i}: {chunk[:100]}...\" if len(chunk) > 100 else f\"\\n  Chunk {i}: {chunk}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load semantic chunks into Qdrant\n",
        "client.create_collection(\n",
        "    collection_name=\"semantic_chunks\",\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "points = [\n",
        "    PointStruct(\n",
        "        id=i,\n",
        "        vector=model.encode(chunk).tolist(),\n",
        "        payload={\"text\": chunk, \"chunk_index\": i},\n",
        "    )\n",
        "    for i, chunk in enumerate(semantic_chunks)\n",
        "]\n",
        "\n",
        "client.upsert(collection_name=\"semantic_chunks\", points=points)\n",
        "print(f\"Loaded {len(points)} semantic chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search\n",
        "query = \"How do I deploy Qdrant?\"\n",
        "query_vec = model.encode(query).tolist()\n",
        "\n",
        "response = client.query_points(\n",
        "    collection_name=\"semantic_chunks\",\n",
        "    query=query_vec,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "for r in response.points:\n",
        "    print(f\"Score: {r.score:.4f}\")\n",
        "    print(f\"  {r.payload['text']}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": { "name": "python", "version": "3.11.0" }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
